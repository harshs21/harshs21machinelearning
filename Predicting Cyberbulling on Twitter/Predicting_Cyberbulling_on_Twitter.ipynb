{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Predicting-Cyberbulling-on-Twitter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VfV-0kvP6PM",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/chantelmariediaz/Predicting-Cyberbulling-on-Twitter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgLTwlrRXYi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3781a70f-4f0a-4a91-ff50-f283c8bb6b66"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjf9o46_XeJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFUunUJ4Xitz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4009690a-50c9-4e71-cba6-49e9759380e0"
      },
      "source": [
        "nltk.download('all')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA8It6smQKKQ",
        "colab_type": "text"
      },
      "source": [
        "Sample of Retrieving Keywords from Twitter API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3pi-lPsV4K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c79055f8-c90d-4482-dab4-8b3e973b8487"
      },
      "source": [
        "# In[1]:\n",
        "\n",
        "\n",
        "#Installing another twitter api library, python-twitter\n",
        "get_ipython().system('pip install python-twitter')\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "#Importing packages and libraries\n",
        "import twitter\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "#Putting credentials \n",
        "api = twitter.Api(consumer_key=\"NRStTXhC2HqBvSv55XXO9sxm5\",\n",
        "  consumer_secret=\"H1jky2hVkgBSzQOVMo0IdmAepZ0wnAldJVGm3QWjjqTQTY8hkf\",\n",
        "  access_token_key=\"955970115576717312-IUAuXEeKIuVxTz9rNm561443N5Gm9sw\",\n",
        "  access_token_secret=\"SCf7PPj3tgFpgXb47nzHlRNRpgH8kEs1i2prLZPkZBExQ\")\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "#Verifying credentials \n",
        "print(api.VerifyCredentials())\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "#Attempting to strip as much emojis as possible by pattern\n",
        "import re\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                          \n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "print(emoji_pattern)\n",
        "\n",
        "#In[56]:\n",
        "#\"curse word\" example: \n",
        "\n",
        "\n",
        "search = api.GetSearch(\"f*#$ you\", count=50)\n",
        "for t in search:\n",
        "    tweets = t.text.lower()\n",
        "    tweets = re.sub(r\"http\\S+\", \"\", tweets)\n",
        "    tweets = tweets.replace(\"…\",\"\")\n",
        "    tweets = tweets.strip()\n",
        "    sentences = sent_tokenize(tweets.replace('\\n',' '))\n",
        "    clean_words = [word for word in sentences if word not in set(string.punctuation)]\n",
        "    characters_to_remove = [\"''\",'``','...']\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "    characters_to_remove2 = [word for word in clean_words if any(letter in sentences for letter in '\\\\')]\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove2)]\n",
        "    print(clean_words)\n",
        "\n",
        "#In[63]:\n",
        "#\"sexuality\" example: \n",
        "\n",
        "\n",
        "search = api.GetSearch(\"you are a p*#$\", count=50)\n",
        "for t in search:\n",
        "    tweets = t.text.lower()\n",
        "    tweets = re.sub(r\"http\\S+\", \"\", tweets)\n",
        "    tweets = tweets.replace(\"…\",\"\")\n",
        "    tweets = tweets.strip()\n",
        "    sentences = sent_tokenize(tweets.replace('\\n',' '))\n",
        "    clean_words = [word for word in sentences if word not in set(string.punctuation)]\n",
        "    characters_to_remove = [\"''\",'``','...']\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "    characters_to_remove2 = [word for word in clean_words if any(letter in sentences for letter in '\\\\')]\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove2)]\n",
        "    print(clean_words)\n",
        "\n",
        "\n",
        "# In[76]:\n",
        "# sample \"mean word/phrase\" example: \n",
        "\n",
        "\n",
        "search = api.GetSearch(\"nobody cares about you\", count=50) # Replace happy with your search\n",
        "for t in search:\n",
        "    tweets = t.text.lower()\n",
        "    tweets = re.sub(r\"http\\S+\", \"\", tweets)\n",
        "    tweets = tweets.replace(\"…\",\"\")\n",
        "    tweets = tweets.strip()\n",
        "    sentences = sent_tokenize(tweets.replace('\\n',' '))\n",
        "    clean_words = [word for word in sentences if word not in set(string.punctuation)]\n",
        "    characters_to_remove = [\"''\",'``','...']\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "    characters_to_remove2 = [word for word in clean_words if any(letter in sentences for letter in '\\\\')]\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove2)]\n",
        "\n",
        "    print(clean_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-twitter in /usr/local/lib/python3.6/dist-packages (3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from python-twitter) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from python-twitter) (0.16.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from python-twitter) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->python-twitter) (3.1.0)\n",
            "{\"created_at\": \"Wed Jan 24 01:06:51 +0000 2018\", \"description\": \"I speak music, python, and Harry Potter. Fluent in rock and quite conversational in jazz, funk, fusion, and many other genres in-between. #Woodshedding\", \"favourites_count\": 3, \"friends_count\": 12, \"id\": 955970115576717312, \"id_str\": \"955970115576717312\", \"name\": \"Chantel Diaz\", \"profile_background_color\": \"000000\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1220537770311061505/jQhrBxlw_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1220537770311061505/jQhrBxlw_normal.jpg\", \"profile_link_color\": \"F58EA8\", \"profile_sidebar_border_color\": \"000000\", \"profile_sidebar_fill_color\": \"000000\", \"profile_text_color\": \"000000\", \"protected\": true, \"screen_name\": \"chmd_\", \"status\": {\"created_at\": \"Mon Aug 13 15:06:54 +0000 2018\", \"favorite_count\": 1, \"id\": 1029021483434160128, \"id_str\": \"1029021483434160128\", \"lang\": \"en\", \"quoted_status_id\": 1027542514356637696, \"quoted_status_id_str\": \"1027542514356637696\", \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"Read my article on GIGsoup #gigsoup #cursive #vitriola https://t.co/UzToxXU0Tl\"}, \"statuses_count\": 6, \"url\": \"https://t.co/bXwjYQAUjk\"}\n",
            "re.compile('[😀-🙏🌀-🗿🚀-\\U0001f6ff\\U0001f1e0-🇿]+')\n",
            "['na, @cbsnews @paynedc not a @teamtrump supporter at all.\\U0001f92a  #youaintblack inside the actual @teamtrump headquarters']\n",
            "['let me point out the obvious: if you are a federal judge and you have to hire an outside lawyer to defend your ruli']\n",
            "['deadline tomorrow!', 'planning to vote in the pa primary election on june 2?', 'we hope you are!', 'this year, try voting f']\n",
            "['@bluemoonjjong @redroseparadise @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt i thought so you ar']\n",
            "['rt @bharatraaval: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "['have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal']\n",
            "[\"@sngwaan ridin' - nct dream dumhdurum - apink where are you?\", '- b.a.p']\n",
            "['&lt; wts / lfb — ph 🇵🇭 only!', '&gt;       - onhand mingyu ode to you polaroid set      - php 180 + lsf      - mop: gcash (p']\n",
            "['have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal']\n",
            "['rt @absapre: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if you a']\n",
            "['rt @dholekarmukta: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "[\"@oommeisaya p'oom!\", 'please cheer up, okay?', \"i don't want you to get sad, you are too nice to be sad for a long time.\", '😔']\n",
            "['rt @sassyshiall: ✨channeled message from your future love✨  🎆retweet, like and comment the thing that you wish on a partner 🎆  🌠followers o']\n",
            "['rt @himadrigoswami3: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.']\n",
            "['rt @abvpmhow: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if you']\n",
            "['i don’t buy anyone’s bullshit, regardless of who they think they are; &amp; that seriously triggers some people’s impos']\n",
            "['@redroseparadise @bluemoonjjong @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt how is me being a f']\n",
            "['@anandmahindra sir watch #contagion  movie  it was shoot back in 2010 and same disease like corona has been shown i']\n",
            "['have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal']\n",
            "['@bleta_p @bluemoonjjong @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt but they do have good enoug']\n",
            "[\"rt @karitaskarisim2: when you meet p'ple that light up your sky in ways unknown.\", 'thank you so much @jokwizklean you are a rare gem and i ap']\n",
            "['@ernagarajan2 @raghavanbm @modernbuddhan @vedhikasuman @tamilanda_ @p_nikumar @prasad_nethaji @muraliathreya']\n",
            "['have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal']\n",
            "['@redroseparadise @bluemoonjjong @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt exactly.', 'if you hav']\n",
            "['p.s.', 'if you are on the mailing list keep your eye out for a special offer  \\U0001f92b😉😊']\n",
            "['rt @ozfacts: @abcnews let’s not beat around the bush people - lives are at stake #nswpol   morrison and gladys don’t care if you get #covid']\n",
            "['rt @cskkanu: @inbreakthrough @ncwindia @un_women @ministrywcd @pmoindia  why you are gender biased against men ❓  why no law for #domesticv']\n",
            "['rt @pandyaharshit: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "['@bleta_p @bluemoonjjong @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt you are just another trash']\n",
            "['rt @pandyaharshit: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "['@bleta_p @redroseparadise @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt you don’t even know who’s']\n",
            "['rt @pandyaharshit: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "[\"@bleta_p @bluemoonjjong @baekh_oney @ggukpianet @kchartsmaster @b_hundred_hyun @bts_twt it's not a fact.\", \"bts aren't\"]\n",
            "['why p/e ratio matters?', \"it's one ratio that provides us with information in regards to what we are paying for what\"]\n",
            "['rt @piyapal6: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if you']\n",
            "['have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal']\n",
            "['rt @tooshyruby: name one woman who hasn’t been fat shamed, skinny shamed, sexually assaulted, harassed in a workplace or catcalled.', 'you pro']\n",
            "['rt @emiliederavin: hope y’all are staying safe &amp; had a good holiday weekend!', 'p.s.don’t forget if you’re bored, i am on @cameo ... just sayi']\n",
            "['rt @charliethepink: so real question... when did maps actually pick up as a term?', 'like,,, no.', 'p*do.', 'please please please if you have any ki']\n",
            "['rt @charliethepink: so real question... when did maps actually pick up as a term?', 'like,,, no.', 'p*do.', 'please please please if you have any ki']\n",
            "[\"rt @karitaskarisim2: when you meet p'ple that light up your sky in ways unknown.\", 'thank you so much @jokwizklean you are a rare gem and i ap']\n",
            "['so real question... when did maps actually pick up as a term?', 'like,,, no.', 'p*do.', 'please please please if you have an']\n",
            "['rt @atirajsinghn: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.', 'if']\n",
            "['rt @prakritisharma_: have p.a.i.n.s.', 'positive attitude in negative situation.', 'live with covid.', 'attempting final year exams is new normal.']\n",
            "['@algrenq @iweidlt @trumpbear4 @saintlarrysins @magatanksue @ana_ssassin19 @gurleysgrl @karabear110 @jcapes_bklyn']\n",
            "['rt @mysterynovel1: thirsty for a new mystery series?', '1 part who-dun-it, 2 parts #thriller, mix with quirky #humor and you have the recipe']\n",
            "['@jeremyrenner \\U0001fa96🇺🇸 thank you to all men and women who served in the arm forces who have sacrifice so much for our fr']\n",
            "['rt @tgradous: @chgocadchic @pjamesjp1 @llmajer @leeone_roz @freelion7 @republikim1 @lauravanoversch @marylene58 @billnsher42197 @madfiest @']\n",
            "['rt @ranaayyub: just blown away by paatal lok.', '@anushkasharma , you are one brave woman to have produced this show.', 'intelligent writing with']\n",
            "['♫ — but as someone else who has the figure of a twelve-year-old girl, do you know how hard it is to feel pretty whe']\n",
            "['@realdonaldtrump nobody cares about your golfing.', 'they care that you have done a terrible job managing the biggest']\n",
            "['for the poor, living in sa over the past 5years has been like suffering catalepsy.', '“you’re presumed dead.', 'are bur']\n",
            "['⠀        nobody cares about your story                       until you win,                           so win.', '⠀']\n",
            "['@therant14 @dpatsmith if you follow their logic, yup.', 'in reality, nobody cares about the civil war except for civ']\n",
            "['@queenofrappeppa @lanascocaiine @popcrave @dojacat at least she has a man to satisfy her, she punched you who is a']\n",
            "[\"rt @itsjefftiedrich: @realdonaldtrump @nytimes move it or don't move it.\", 'nobody but your easily-conned worshipers cares about your latest m']\n",
            "['if you think nobody cares about you, try missing a couple of payments.', '假如你认为没有人关心你，试试拖欠一下应付款。-- 加菲猫']\n",
            "['nobody cares about what you have to say or what you feel until you stop caring about what they say or how they feel.']\n",
            "['@julius_s_malema @mmusimaimane @presidencyza @_africanunion julius nobody cares about you.. shut up']\n",
            "[\"rt @zeynabsheriff: and if you're one of those girls that thinks you're better than other girls because you don't show skin.\", \"i'm here to tel\"]\n",
            "[\"@gkuhlenschmidt here's the thing bitch!!!\", 'nobody cares about your opinion nor you please kill yourself🤡']\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "[\"rt @yeonatwc: nobody owns any concepts and aren't y'all tired of accusing plagiarism to twice?\", \"twice doesn't even cares about your faves, a\"]\n",
            "['rt @dear_priyanka1: nobody cares about your degree when you drive a lamborghini.']\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "[\"rt @zeynabsheriff: and if you're one of those girls that thinks you're better than other girls because you don't show skin.\", \"i'm here to tel\"]\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "['@ahamadnooh @lord_selby nobody cares about islamic achievements you are preaching to the choir']\n",
            "['nobody cares   worry about yourself, your family and the people who are important to you']\n",
            "['rt @odysseyellie: there it is !', 'a (simple) render of ellie just to show what she looks like in c4d :3 (and i forgot to show the back but no']\n",
            "['@piersmorgan you do know literally nobody cares about this.', 'unless your a politician, a reporter or part of the gut']\n",
            "[\"rt @itsjefftiedrich: @realdonaldtrump @nytimes move it or don't move it.\", 'nobody but your easily-conned worshipers cares about your latest m']\n",
            "['@skynews @stephen_dorrell nobody cares,look at the beaches yesterday nobody gives a toss about social distancing no']\n",
            "['@donniebets1 @arabylilac @travisakers dude gtfo, nobody cares what you and your trump loving ass gotta bring to the']\n",
            "['please resign.', 'nobody cares about your insights anymore.', 'the public has lost faith in you.', 'even phapi is appealing']\n",
            "['@bbcbreaking @piersmorgan @itvnews @skynewsbreak the deaths from this pandemic are on you, nobody else.', 'all you bit']\n",
            "[\"rt @richtandy1: @gmb @ranvir01 nobody outside side of london cares, talk about emerdale its the only thing you're qualified for.\"]\n",
            "['@skyshaymins nobody cares if you draw porn because most people in the industry draw it and dont care because theyre']\n",
            "[\"rt @itsjefftiedrich: @realdonaldtrump @nytimes move it or don't move it.\", 'nobody but your easily-conned worshipers cares about your latest m']\n",
            "[\"@rimflim @pryshott @fortnitestatus you can't secure a spot before they take everything away.\", 'so now your just sitti']\n",
            "['rt @thehowie: @realdonaldtrump nobody cares about your golfing.', 'they care that you have done a terrible job managing the biggest crisis of']\n",
            "[\"rt @yeonatwc: nobody owns any concepts and aren't y'all tired of accusing plagiarism to twice?\", \"twice doesn't even cares about your faves, a\"]\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "['rt @sorealwords: nobody cares about your story until you win, so win.', '💪🏻']\n",
            "['@savannahlmaddox @kysportsradio nobody cares about mj, but we do care about your response.', 'you have failed to conde']\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "[\"@gmb @ranvir01 nobody outside side of london cares, talk about emerdale its the only thing you're qualified for.\"]\n",
            "['rt @janmajit07: @mohit_db10 yes, unfortunately, ppl only understand their own problem but they give a damn about others.', 'so, the best way i']\n",
            "['@mohit_db10 yes, unfortunately, ppl only understand their own problem but they give a damn about others.', 'so, the be']\n",
            "[\"i am sure they don't care 2 hoots about whether or not a nobody cares!\", \"it is migrant workers, they don't even know\"]\n",
            "[\"rt @zeynabsheriff: and if you're one of those girls that thinks you're better than other girls because you don't show skin.\", \"i'm here to tel\"]\n",
            "[\"@kmart_wins @kickssofstephan @frogsprinter3 @allstros much lighter and they didn't steal a series.\", 'i heard they got']\n",
            "[\"rt @itsjefftiedrich: @realdonaldtrump @nytimes move it or don't move it.\", 'nobody but your easily-conned worshipers cares about your latest m']\n",
            "['rt @ikashafarey7: just live your life, nobody cares.', 'if you still care about others, for surely you’ll never find your own happiness 💯']\n",
            "['@pieglowing @uviqueroblox @warriormappy shut your dumbass up with ur baby yoda ass pfp.', 'nobody asked for your opini']\n",
            "['rt @heynotebook: nobody cares about your story until you win, so win.', '💪🏻']\n",
            "['@hawklikesslife you said nobody cares about the wnba.', 'she said kobe did.', 'not you.', 'kobe.', 'it ain’t difficult to comprehend that']\n",
            "['@imoftenbanned @normajennings88 @ts_jammy @volcel2020 @zeroasalimit @midibitch nobody in the world gives a shit how']\n",
            "[\"rt @yeonatwc: nobody owns any concepts and aren't y'all tired of accusing plagiarism to twice?\", \"twice doesn't even cares about your faves, a\"]\n",
            "['rt @skopylonky: this life, nobody cares about your story until you win so sadly .', '👂👂  listen to kalowo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwAAsXh0QTT8",
        "colab_type": "text"
      },
      "source": [
        "Predicting+Cyberbullying+Twitter+ Code1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRMU1wAV6Sn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ee74c94-ab33-4f0e-a2dd-a42a1df622f3"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "import string \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "#Load dataset\n",
        "import pandas as pd\n",
        "df1 = pd.read_csv(\"cleanprojectdataset.csv\")\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "#Tokenize words and labels into lists\n",
        "\n",
        "Tweet = []\n",
        "Labels = []\n",
        "\n",
        "for row in df1[\"Tweet\"]:\n",
        "    #tokenize words\n",
        "    words = word_tokenize(row)\n",
        "    #remove punctuations\n",
        "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
        "    #remove stop words\n",
        "    english_stops = set(stopwords.words('english'))\n",
        "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
        "    clean_words = [word for word in clean_words if word not in english_stops]\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "    #Lematise words\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
        "    Tweet.append(lemma_list)\n",
        "\n",
        "    for row in df1[\"Text Label\"]:\n",
        "        Labels.append(row)\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "#combine them to create bag of words\n",
        "combined = zip(Tweet, Labels)\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "#Create bag of words and dictionary object\n",
        "def bag_of_words(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "#Key, Value Pair into new list for modeling\n",
        "Final_Data = []\n",
        "for r, v in combined:\n",
        "    bag_of_words(r)\n",
        "    Final_Data.append((bag_of_words(r),v))\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "#random shuffle\n",
        "import random\n",
        "random.shuffle(Final_Data)\n",
        "print(len(Final_Data))\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "#Split the data into training set and testing 60/40 split\n",
        "train_set, test_set = Final_Data[0:746], Final_Data[746:]\n",
        "\n",
        "#import confusion matrix metrics and run Naive Bayes with Unigrams\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "\n",
        "#find accuracy\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "\n",
        "print(\"Naive Bayes Performance with Unigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "#find recall\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "nbrefset = collections.defaultdict(set)\n",
        "nbtestset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    nbrefset[label].add(i)\n",
        "    observed = nb_classifier.classify(feats)\n",
        "    nbtestset[observed].add(i)\n",
        "print(\"UnigramNB Recall\")\n",
        "print('Bullying recall:', recall(nbtestset['Bullying'], nbrefset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "#find most informative features\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "#Run Decision Tree for Unigrams to find recall\n",
        "\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"UnigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "#Run Maxent Classifier for Unigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"UnigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        " \n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "#Run Support Vector Machine for Unigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"UniigramSVM Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "#Do the same thing with bigrams\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[37]:\n",
        "\n",
        "#Bag of words for bigrams\n",
        "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)  \n",
        "    bigrams = bigram_finder.nbest(score_fn, n)  \n",
        "    return bag_of_words(bigrams)\n",
        "\n",
        "\n",
        "# In[38]:\n",
        "\n",
        "\n",
        "Final_Data2 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_bigrams_words(z)\n",
        "    Final_Data2.append((bag_of_bigrams_words(z),e))\n",
        "\n",
        "\n",
        "# In[39]:\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data2)\n",
        "print(len(Final_Data2))\n",
        "\n",
        "#split data again around 60/40\n",
        "\n",
        "train_set, test_set = Final_Data2[0:747], Final_Data2[747:]\n",
        "\n",
        "#Naive Bayes for Bigrams\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "#Accuracy\n",
        "\n",
        "print(\"Naive Bayes Performance with Bigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[40]:\n",
        "\n",
        "#Informative Features for Bigrams\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[41]:\n",
        "\n",
        "#Decision Tree for Bigrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"BigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "#Maxent Classifier for Bigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"BigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        " \n",
        "\n",
        "\n",
        "# In[43]:\n",
        "\n",
        "#Support Vecotr Machine for Bigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Bigrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[62]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[63]:\n",
        "\n",
        "#Same thing with Trigrams\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "#Bag of words for Trigrams\n",
        "def bag_of_trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq, n=200):\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(words)  \n",
        "    trigrams = trigram_finder.nbest(score_fn, n)  \n",
        "    return bag_of_words(trigrams)\n",
        "\n",
        "\n",
        "# In[64]:\n",
        "\n",
        "#Final list for modeling\n",
        "Final_Data3 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_trigrams_words(z)\n",
        "    Final_Data3.append((bag_of_trigrams_words(z),e))\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data3)\n",
        "print(len(Final_Data3))\n",
        "\n",
        "#60/40\n",
        "train_set, test_set = Final_Data3[0:747], Final_Data3[747:]\n",
        "\n",
        "#Naive Bayes for Trigrams\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "#Accuracy\n",
        "print(\"Naive Bayes Performance with Trigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[67]:\n",
        "\n",
        "#Metrics\n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "\n",
        "\n",
        "# In[66]:\n",
        "\n",
        "#Most informative features for Trigrams\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[47]:\n",
        "\n",
        "#Decision Tree for Trigrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"TrigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[48]:\n",
        "\n",
        "#Maxent Classifier for Trigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"TrigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[49]:\n",
        "\n",
        "#Support Vector Machine for Trigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Trigrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[50]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[51]:\n",
        "\n",
        "#Combining Unigrams, Bigrams, and Trigrams for (N=3) modeling\n",
        "\n",
        "# Import Bigram metrics - we will use these to identify the top 200 trigrams\n",
        "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    return bigrams\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "\n",
        "# Import Trigram metrics - we will use these to identify the top 200 trigrams\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
        "    trigrams = trigram_finder.nbest(score_fn, n)\n",
        "    return trigrams\n",
        "\n",
        "#Combined\n",
        "def bag_of_Ngrams_words(words):\n",
        "    bigramBag = bigrams_words(words)\n",
        "    \n",
        "    #The following two for loops convert tuple into string\n",
        "    for b in range(0,len(bigramBag)):\n",
        "        bigramBag[b]=' '.join(bigramBag[b])\n",
        "   \n",
        "    trigramBag = trigrams_words(words)\n",
        "    for t in range(0,len(trigramBag)):\n",
        "        trigramBag[t]=' '.join(trigramBag[t])\n",
        "        \n",
        " #New bag of words\n",
        "\n",
        "    return bag_of_words(trigramBag + bigramBag + words)\n",
        "\n",
        "\n",
        "# In[52]:\n",
        "\n",
        "\n",
        "Final_Data4 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_Ngrams_words(z)\n",
        "    Final_Data4.append((bag_of_Ngrams_words(z),e))\n",
        "\n",
        "\n",
        "# In[58]:\n",
        "\n",
        "#Naive Bayes for Ngrams\n",
        "import random\n",
        "random.shuffle(Final_Data4)\n",
        "print(len(Final_Data4))\n",
        "\n",
        "train_set, test_set = Final_Data4[0:747], Final_Data4[747:]\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "#Accuracy\n",
        "print(\"Naive Bayes Performance with Ngrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[59]:\n",
        "\n",
        "#Informative features for Ngrams\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[60]:\n",
        "\n",
        "\n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "\n",
        "\n",
        "# In[55]:\n",
        "\n",
        "#Decision Tree for Ngrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"NgramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[56]:\n",
        "\n",
        "#Maxent Classifier, Logistic Regression for Ngrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"NgramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[57]:\n",
        "\n",
        "#Support Vector Machine for Ngrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Ngrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "#Printing with more measures, example below\n",
        "# In[41]:\n",
        "\n",
        "\n",
        "train_set, test_set = Final_Data[0:747], Final_Data[747:]\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(nb_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = nb_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Tweet    Text Label\n",
            "0     .omg why are poc wearing fugly blue contacts s...  Non-Bullying\n",
            "1     .Sorry but most of the runners popular right n...  Non-Bullying\n",
            "2     .those jeans are hideous, and I?m afraid he?s ...  Non-Bullying\n",
            "3     .I had to dress up for a presentation in class...  Non-Bullying\n",
            "4     .Am I the only one who thinks justin bieber is...  Non-Bullying\n",
            "...                                                 ...           ...\n",
            "1060  No we are not, But you are a race baiting libt...      Bullying\n",
            "1061  you wont get anyone for this challenge., after...      Bullying\n",
            "1062  I will follow you if you are not a libtard,Mus...      Bullying\n",
            "1063  michaelianblack Ur a child, an ostrich w/ your...      Bullying\n",
            "1064  FoxNews. not to all the ppl I know that live t...      Bullying\n",
            "\n",
            "[1065 rows x 2 columns]\n",
            "1065\n",
            "Naive Bayes Performance with Unigrams \n",
            "Accuracy: 0.664576802507837\n",
            "UnigramNB Recall\n",
            "Bullying recall: 0.5714285714285714\n",
            "\n",
            "Most Informative Features\n",
            "                     low = True           Bullyi : Non-Bu =      8.7 : 1.0\n",
            "                      .i = True           Non-Bu : Bullyi =      6.9 : 1.0\n",
            "                     fat = True           Bullyi : Non-Bu =      6.3 : 1.0\n",
            "                 libtard = True           Bullyi : Non-Bu =      5.8 : 1.0\n",
            "                   piece = True           Bullyi : Non-Bu =      5.8 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                   mouth = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                    last = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                   sorry = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                    shut = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "UnigramDT Recall\n",
            "Bullying recall: 0.7678571428571429\n",
            "\n",
            "UnigramsLogit Recall\n",
            "Bullying recall: 0.6173913043478261\n",
            "\n",
            "UniigramSVM Recall\n",
            "Bullying recall: 0.5905511811023622\n",
            "1065\n",
            "Naive Bayes Performance with Bigrams \n",
            "Accuracy: 0.6761006289308176\n",
            "Most Informative Features\n",
            "           ('low', 'iq') = True           Bullyi : Non-Bu =     19.5 : 1.0\n",
            "       ('piece', 'shit') = True           Bullyi : Non-Bu =     15.0 : 1.0\n",
            "  ('worthless', 'piece') = True           Bullyi : Non-Bu =      8.2 : 1.0\n",
            "   ('fucking', 'retard') = True           Bullyi : Non-Bu =      4.4 : 1.0\n",
            "     ('fucking', 'cunt') = True           Bullyi : Non-Bu =      3.4 : 1.0\n",
            "          ('dumb', 'as') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "     ('white', 'people') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "     ('asshole', 'like') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "   ('pathetic', 'loser') = True           Bullyi : Non-Bu =      2.3 : 1.0\n",
            "      ('nobody', 'care') = True           Bullyi : Non-Bu =      2.2 : 1.0\n",
            "BigramDT Recall\n",
            "Bullying recall: 0.6785714285714286\n",
            "\n",
            "BigramsLogit Recall\n",
            "Bullying recall: 0.6666666666666666\n",
            "\n",
            "Bigrams Recall\n",
            "Bullying recall: 0.3973509933774834\n",
            "1065\n",
            "Naive Bayes Performance with Trigrams \n",
            "Accuracy: 0.5660377358490566\n",
            "bullying precision: 0.8\n",
            "bullying recall: 0.05555555555555555\n",
            "Most Informative Features\n",
            "('worthless', 'piece', 'shit') = True           Bullyi : Non-Bu =     10.4 : 1.0\n",
            "('woman', 'idiot', 'fag') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('also', 'beating', 'woman') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('w/arabism', 'clueless', '+not') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('feign', 'objectivity', 'goose') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "(\"don\\\\'t\", 'identify', 'w/arabism') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('stepping', 'nazi', 'hive') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('identify', 'w/arabism', 'clueless') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('another', 'low', 'iq') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "('beating', 'woman', 'idiot') = True           Bullyi : Non-Bu =      1.6 : 1.0\n",
            "TrigramDT Recall\n",
            "Bullying recall: 0.6\n",
            "\n",
            "TrigramsLogit Recall\n",
            "Bullying recall: 0.8\n",
            "\n",
            "Trigrams Recall\n",
            "Bullying recall: 0.8\n",
            "1065\n",
            "Naive Bayes Performance with Ngrams \n",
            "Accuracy: 0.6823899371069182\n",
            "Most Informative Features\n",
            "              piece shit = True           Bullyi : Non-Bu =     14.8 : 1.0\n",
            "                  low iq = True           Bullyi : Non-Bu =      8.8 : 1.0\n",
            "         worthless piece = True           Bullyi : Non-Bu =      8.7 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      8.3 : 1.0\n",
            "    worthless piece shit = True           Bullyi : Non-Bu =      7.7 : 1.0\n",
            "                      ur = True           Bullyi : Non-Bu =      7.7 : 1.0\n",
            "                   piece = True           Bullyi : Non-Bu =      7.2 : 1.0\n",
            "                     low = True           Bullyi : Non-Bu =      6.9 : 1.0\n",
            "                     old = True           Bullyi : Non-Bu =      6.6 : 1.0\n",
            "                     big = True           Bullyi : Non-Bu =      5.6 : 1.0\n",
            "bullying precision: 0.6131386861313869\n",
            "bullying recall: 0.6363636363636364\n",
            "NgramDT Recall\n",
            "Bullying recall: 0.813953488372093\n",
            "\n",
            "NgramsLogit Recall\n",
            "Bullying recall: 0.7083333333333334\n",
            "\n",
            "Ngrams Recall\n",
            "Bullying recall: 0.711340206185567\n",
            "Most Informative Features\n",
            "                     low = True           Bullyi : Non-Bu =      8.6 : 1.0\n",
            "                      .i = True           Non-Bu : Bullyi =      6.9 : 1.0\n",
            "                     fat = True           Bullyi : Non-Bu =      6.3 : 1.0\n",
            "                 libtard = True           Bullyi : Non-Bu =      5.8 : 1.0\n",
            "                   piece = True           Bullyi : Non-Bu =      5.8 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                   mouth = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                    last = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                   sorry = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                    shut = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "0.6666666666666666\n",
            "bullying precision: 0.5714285714285714\n",
            "bullying recall: 0.6875\n",
            "bullying F-measure: 0.624113475177305\n",
            "not-bullying precision: 0.7560975609756098\n",
            "not-bullying recall: 0.6526315789473685\n",
            "not-bullying F-measure: 0.7005649717514125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1WcmP6hQcqO",
        "colab_type": "text"
      },
      "source": [
        "Predicting+Cyberbullying+Code+2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_y_2GTXYtFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65e3a9a0-22d0-4ace-d58e-c1d07655b280"
      },
      "source": [
        "# coding: utf-8\n",
        "#Same modeling, slightly different code with similar results\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "import string \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "#import dataset\n",
        "import pandas as pd\n",
        "df1 = pd.read_csv(\"cleanprojectdataset.csv\")\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "#Create lists for tweets and label\n",
        "Tweet = []\n",
        "Labels = []\n",
        "\n",
        "for row in df1[\"Tweet\"]:\n",
        "    #tokenize words\n",
        "    words = word_tokenize(row)\n",
        "    #remove punctuations\n",
        "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
        "    #remove stop words\n",
        "    english_stops = set(stopwords.words('english'))\n",
        "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
        "    clean_words = [word for word in clean_words if word not in english_stops]\n",
        "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
        "    #Lematise words\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
        "    Tweet.append(lemma_list)\n",
        "\n",
        "    for row in df1[\"Text Label\"]:\n",
        "        Labels.append(row)\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "#Combine lists\n",
        "combined = zip(Tweet, Labels)\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "#Create bag of words\n",
        "def bag_of_words(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "#Create new list for modeling\n",
        "Final_Data = []\n",
        "for r, v in combined:\n",
        "    bag_of_words(r)\n",
        "    Final_Data.append((bag_of_words(r),v))\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data)\n",
        "print(len(Final_Data))\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "#Split the data into training and test\n",
        "train_set, test_set = Final_Data[0:746], Final_Data[746:]\n",
        "\n",
        "#Naive Bayes for Unigramsm check accuracy\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "print(\"Naive Bayes Performance with Unigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "#Naive Bayes for Unigrams, Recall Measure\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "nbrefset = collections.defaultdict(set)\n",
        "nbtestset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    nbrefset[label].add(i)\n",
        "    observed = nb_classifier.classify(feats)\n",
        "    nbtestset[observed].add(i)\n",
        "print(\"UnigramNB Recall\")\n",
        "print('Bullying recall:', recall(nbtestset['Bullying'], nbrefset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "#Find most informative features\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "#Decision Tree for Unigrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"UnigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "#Logisitic Regression for Unigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"UnigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        " \n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "#Support Vector Machine for Unigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"UnigramSVM Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "#Same thing with Bigrams\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "#Bag of Words of Bigrams\n",
        "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)  \n",
        "    bigrams = bigram_finder.nbest(score_fn, n)  \n",
        "    return bag_of_words(bigrams)\n",
        "\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "\n",
        "Final_Data2 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_bigrams_words(z)\n",
        "    Final_Data2.append((bag_of_bigrams_words(z),e))\n",
        "\n",
        "\n",
        "# In[19]:\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data2)\n",
        "print(len(Final_Data2))\n",
        "\n",
        "train_set, test_set = Final_Data2[0:747], Final_Data2[747:]\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "#Naive Bayes for Bigrams\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "\n",
        "print(\"Naive Bayes Performance with Bigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[20]:\n",
        "\n",
        "\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[21]:\n",
        "\n",
        "\n",
        "print(\"BigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "#Decision Tree for Bigrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"BigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[23]:\n",
        "\n",
        "#Logistic Regression for Bigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"BigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        " \n",
        "\n",
        "\n",
        "# In[24]:\n",
        "\n",
        "#Support Vector Machine for Bigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Bigrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "#Same thing with Trigrams\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "def bag_of_trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq, n=200):\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(words)  \n",
        "    trigrams = trigram_finder.nbest(score_fn, n)  \n",
        "    return bag_of_words(trigrams)\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "Final_Data3 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_trigrams_words(z)\n",
        "    Final_Data3.append((bag_of_trigrams_words(z),e))\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data3)\n",
        "print(len(Final_Data3))\n",
        "\n",
        "train_set, test_set = Final_Data3[0:747], Final_Data3[747:]\n",
        "\n",
        "#Naive Bayes for Trigrams\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "\n",
        "print(\"Naive Bayes Performance with Trigrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "\n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "#Decision Tree for Trigrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"TrigramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[48]:\n",
        "\n",
        "#Logistic Regression for Trigrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"TrigramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "#Support Vector Machine for Trigrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Trigrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "combined = zip(Tweet,Labels)\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "#Combine both unigrams, bigrams, and trigrams\n",
        "\n",
        "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
        "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    return bigrams\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "\n",
        "# Import Bigram metrics - we will use these to identify the top 200 trigrams \n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
        "    trigrams = trigram_finder.nbest(score_fn, n)\n",
        "    return trigrams\n",
        "\n",
        "#bag of ngrams\n",
        "def bag_of_Ngrams_words(words):\n",
        "    bigramBag = bigrams_words(words)\n",
        "    \n",
        "    #The following two for loops convert tuple into string\n",
        "    for b in range(0,len(bigramBag)):\n",
        "        bigramBag[b]=' '.join(bigramBag[b])\n",
        "   \n",
        "    trigramBag = trigrams_words(words)\n",
        "    for t in range(0,len(trigramBag)):\n",
        "        trigramBag[t]=' '.join(trigramBag[t])\n",
        "\n",
        "    return bag_of_words(trigramBag + bigramBag + words)\n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "\n",
        "Final_Data4 =[]\n",
        "\n",
        "for z, e in combined:\n",
        "    bag_of_Ngrams_words(z)\n",
        "    Final_Data4.append((bag_of_Ngrams_words(z),e))\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data4)\n",
        "print(len(Final_Data4))\n",
        "\n",
        "train_set, test_set = Final_Data4[0:747], Final_Data4[747:]\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
        "from nltk import metrics\n",
        "#Naive Bayes for Ngrams\n",
        "\n",
        "refsets = collections. defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "\n",
        "\n",
        "print(\"Naive Bayes Performance with Ngrams \")    \n",
        "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "\n",
        "# In[59]:\n",
        "\n",
        "\n",
        "classifier.show_most_informative_features(n=10)\n",
        "\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "\n",
        "\n",
        "# In[37]:\n",
        "\n",
        "#Decision Tree for Ngrams\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "refset = collections.defaultdict(set)\n",
        "testset = collections.defaultdict(set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = dt_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"NgramDT Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[38]:\n",
        "\n",
        "#Logistic Regression for Ngrams\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = logit_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "print(\"NgramsLogit Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# In[39]:\n",
        "\n",
        "#Support Vector Machine for Ngrams\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        " \n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refset[label].add(i)\n",
        "    observed = SVM_classifier.classify(feats)\n",
        "    testset[observed].add(i)\n",
        "    \n",
        "print(\"Trigrams Recall\")\n",
        "print('Bullying recall:', recall(testset['Bullying'], refset['Bullying']))\n",
        "\n",
        "\n",
        "# In[41]:\n",
        "\n",
        "\n",
        "train_set, test_set = Final_Data[0:747], Final_Data[747:]\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(nb_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = nb_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "import collections\n",
        "from nltk import metrics\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(dt_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = dt_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('non-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('non-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('non-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "#Create Logistic Regression model to compare\n",
        "from nltk.classify import MaxentClassifier\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        " \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = logit_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "  \n",
        "print('pos precision:', precision(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('pos recall:', recall(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "\n",
        "# SVM model\n",
        "\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        "\n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = SVM_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('pos precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('pos recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "\n",
        "zl = zip(Tweet,Labels)\n",
        "\n",
        "#define a bag_of_words function to return word, True.\n",
        "\n",
        "def bag_of_words(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "def bag_of_words_not_in_set(words, badwords):\n",
        "    return bag_of_words(set(words) - set(badwords))\n",
        "\n",
        "# Define another function that will return words that are in words, but not in badwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#define a bag_of_non_stopwords function to return word, True.\n",
        "\n",
        "def bag_of_non_stopwords(words, stopfile='english'):\n",
        "    badwords = stopwords.words(stopfile)\n",
        "    return bag_of_words_not_in_set(words, badwords)\n",
        "\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "\n",
        "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    return bag_of_words(bigrams)\n",
        "    \n",
        "    bigrams = bag_of_bigrams_words(words)\n",
        "\n",
        "#Creating our unigram featureset dictionary for modeling\n",
        "\n",
        "Final_Data = []\n",
        "\n",
        "for k, v in zl:\n",
        "    bag_of_bigrams_words(k)\n",
        "    Final_Data.append((bag_of_bigrams_words(k),v))\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data)\n",
        "\n",
        "#splits the data around 70% of 500 *350 reviews* for both testing and training\n",
        "\n",
        "train_set, test_set = Final_Data[0:778], Final_Data[778:]\n",
        "\n",
        "#Now we will calculate accuracy, precision, recall, and f-measure using Naives Bayes classifier\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(nb_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = nb_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[44]:\n",
        "\n",
        "\n",
        "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    return bigrams\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "\n",
        "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
        "n=200):\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
        "    trigrams = trigram_finder.nbest(score_fn, n)\n",
        "    return trigrams\n",
        "\n",
        "\n",
        "def bag_of_Ngrams_words(words):\n",
        "    bigramBag = bigrams_words(words)\n",
        "    \n",
        "    #The following two for loops convert tuple into string\n",
        "    for b in range(0,len(bigramBag)):\n",
        "        bigramBag[b]=' '.join(bigramBag[b])\n",
        "   \n",
        "    trigramBag = trigrams_words(words)\n",
        "    for t in range(0,len(trigramBag)):\n",
        "        trigramBag[t]=' '.join(trigramBag[t])\n",
        "\n",
        "    return bag_of_words(trigramBag + bigramBag + words)\n",
        "\n",
        "\n",
        "# In[47]:\n",
        "\n",
        "\n",
        "zl = zip(Tweet,Labels)\n",
        "\n",
        "Final_Data = []\n",
        "\n",
        "for k, v in zl:\n",
        "    bag_of_words(k)\n",
        "    Final_Data.append((bag_of_words(k),v))\n",
        "\n",
        "import random\n",
        "random.shuffle(Final_Data)\n",
        "\n",
        "#splits the data around 70% of 500 *350 reviews* for both testing and training\n",
        "\n",
        "train_set, test_set = Final_Data[0:778], Final_Data[778:]\n",
        "\n",
        "#Now we will calculate accuracy, precision, recall, and f-measure using Naives Bayes classifier\n",
        "\n",
        "import nltk\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(nb_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = nb_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('not-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('not-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[48]:\n",
        "\n",
        "\n",
        "import collections\n",
        "from nltk import metrics\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
        "                                             binary=True, \n",
        "                                             entropy_cutoff=0.8, \n",
        "                                             depth_cutoff=5, \n",
        "                                             support_cutoff=30)\n",
        "from nltk.classify.util import accuracy\n",
        "print(accuracy(dt_classifier, test_set))\n",
        "\n",
        "refsets = collections.defaultdict(set)\n",
        "testsets = collections.defaultdict(set)\n",
        "    \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = dt_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('bullying precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('bullying F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('non-bullying precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('non-bullying recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('non-bullying F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[49]:\n",
        "\n",
        "\n",
        "#Create Logistic Regression model to compare\n",
        "from nltk.classify import MaxentClassifier\n",
        "import collections\n",
        "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
        "\n",
        "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
        " \n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = logit_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "  \n",
        "print('pos precision:', precision(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('pos recall:', recall(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Non-Bullying']))\n",
        "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "\n",
        "\n",
        "# In[50]:\n",
        "\n",
        "\n",
        "# SVM model\n",
        "\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
        "\n",
        "for i, (Final_Data, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = SVM_classifier.classify(Final_Data)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "print('pos precision:', precision(refsets['Bullying'], testsets['Bullying']))\n",
        "print('pos recall:', recall(refsets['Bullying'], testsets['Bullying']))\n",
        "print('pos F-measure:', f_measure(refsets['Bullying'], testsets['Bullying']))\n",
        "print('neg precision:', precision(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg recall:', recall(refsets['Non-Bullying'], testsets['Non-Bullying']))\n",
        "print('neg F-measure:', f_measure(refsets['Non-Bullying'], testsets['Non-Bullying']))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Tweet    Text Label\n",
            "0     .omg why are poc wearing fugly blue contacts s...  Non-Bullying\n",
            "1     .Sorry but most of the runners popular right n...  Non-Bullying\n",
            "2     .those jeans are hideous, and I?m afraid he?s ...  Non-Bullying\n",
            "3     .I had to dress up for a presentation in class...  Non-Bullying\n",
            "4     .Am I the only one who thinks justin bieber is...  Non-Bullying\n",
            "...                                                 ...           ...\n",
            "1060  No we are not, But you are a race baiting libt...      Bullying\n",
            "1061  you wont get anyone for this challenge., after...      Bullying\n",
            "1062  I will follow you if you are not a libtard,Mus...      Bullying\n",
            "1063  michaelianblack Ur a child, an ostrich w/ your...      Bullying\n",
            "1064  FoxNews. not to all the ppl I know that live t...      Bullying\n",
            "\n",
            "[1065 rows x 2 columns]\n",
            "1065\n",
            "Naive Bayes Performance with Unigrams \n",
            "Accuracy: 0.6144200626959248\n",
            "UnigramNB Recall\n",
            "Bullying recall: 0.5394736842105263\n",
            "\n",
            "Most Informative Features\n",
            "                   piece = True           Bullyi : Non-Bu =      9.1 : 1.0\n",
            "                feminism = True           Non-Bu : Bullyi =      8.8 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      7.8 : 1.0\n",
            "                      .i = True           Non-Bu : Bullyi =      6.7 : 1.0\n",
            "                 someone = True           Non-Bu : Bullyi =      6.7 : 1.0\n",
            "                    keep = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                   sorry = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                      ur = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                   thing = True           Non-Bu : Bullyi =      5.4 : 1.0\n",
            "                 libtard = True           Bullyi : Non-Bu =      5.3 : 1.0\n",
            "UnigramDT Recall\n",
            "Bullying recall: 0.7\n",
            "\n",
            "UnigramsLogit Recall\n",
            "Bullying recall: 0.631578947368421\n",
            "\n",
            "UnigramSVM Recall\n",
            "Bullying recall: 0.6036036036036037\n",
            "1065\n",
            "Naive Bayes Performance with Bigrams \n",
            "Accuracy: 0.6666666666666666\n",
            "Most Informative Features\n",
            "       ('piece', 'shit') = True           Bullyi : Non-Bu =     17.4 : 1.0\n",
            "  ('worthless', 'piece') = True           Bullyi : Non-Bu =     10.4 : 1.0\n",
            "           ('low', 'iq') = True           Bullyi : Non-Bu =      9.4 : 1.0\n",
            "     ('fucking', 'cunt') = True           Bullyi : Non-Bu =      2.5 : 1.0\n",
            "          ('dumb', 'as') = True           Bullyi : Non-Bu =      2.5 : 1.0\n",
            "       ('smell', 'like') = True           Bullyi : Non-Bu =      2.5 : 1.0\n",
            "          ('fag', 'lol') = True           Bullyi : Non-Bu =      2.5 : 1.0\n",
            "('theellenshow', '.kamalaharris') = True           Bullyi : Non-Bu =      2.5 : 1.0\n",
            "        ('look', 'like') = True           Bullyi : Non-Bu =      2.1 : 1.0\n",
            "      ('nobody', 'care') = True           Bullyi : Non-Bu =      2.0 : 1.0\n",
            "BigramDT Recall\n",
            "Bullying recall: 0.6036036036036037\n",
            "\n",
            "BigramDT Recall\n",
            "Bullying recall: 0.8\n",
            "\n",
            "BigramsLogit Recall\n",
            "Bullying recall: 0.6774193548387096\n",
            "\n",
            "Bigrams Recall\n",
            "Bullying recall: 0.6774193548387096\n",
            "1065\n",
            "Naive Bayes Performance with Trigrams \n",
            "Accuracy: 0.6415094339622641\n",
            "bullying precision: 0.75\n",
            "bullying recall: 0.075\n",
            "Most Informative Features\n",
            "('worthless', 'piece', 'shit') = True           Bullyi : Non-Bu =      9.1 : 1.0\n",
            "('need', 'look', 'european') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "(\"'one\", 'need', 'look') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('illegals', 'threat', 'idiot') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('dope', 'like', 'junky') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('fugly', 'smoking', 'dope') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('look', 'european', 'country') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('threat', 'idiot', \"'one\") = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('smoking', 'dope', 'like') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "('think', 'illegals', 'threat') = True           Bullyi : Non-Bu =      1.4 : 1.0\n",
            "TrigramDT Recall\n",
            "Bullying recall: 0.8\n",
            "\n",
            "TrigramsLogit Recall\n",
            "Bullying recall: 0.75\n",
            "\n",
            "Trigrams Recall\n",
            "Bullying recall: 0.3801916932907348\n",
            "1065\n",
            "Naive Bayes Performance with Ngrams \n",
            "Accuracy: 0.660377358490566\n",
            "Most Informative Features\n",
            "               worthless = True           Bullyi : Non-Bu =     13.5 : 1.0\n",
            "                  low iq = True           Bullyi : Non-Bu =     10.0 : 1.0\n",
            "                   piece = True           Bullyi : Non-Bu =      9.9 : 1.0\n",
            "                     low = True           Bullyi : Non-Bu =      9.8 : 1.0\n",
            "                 someone = True           Non-Bu : Bullyi =      7.8 : 1.0\n",
            "                      iq = True           Bullyi : Non-Bu =      7.3 : 1.0\n",
            "                      .i = True           Non-Bu : Bullyi =      6.9 : 1.0\n",
            "                      ur = True           Bullyi : Non-Bu =      6.5 : 1.0\n",
            "               prejudice = True           Non-Bu : Bullyi =      6.0 : 1.0\n",
            "                  retard = True           Bullyi : Non-Bu =      5.6 : 1.0\n",
            "bullying precision: 0.5714285714285714\n",
            "bullying recall: 0.6511627906976745\n",
            "NgramDT Recall\n",
            "Bullying recall: 0.6964285714285714\n",
            "\n",
            "NgramsLogit Recall\n",
            "Bullying recall: 0.6285714285714286\n",
            "\n",
            "Trigrams Recall\n",
            "Bullying recall: 0.5886524822695035\n",
            "Most Informative Features\n",
            "                   piece = True           Bullyi : Non-Bu =      9.1 : 1.0\n",
            "                feminism = True           Non-Bu : Bullyi =      8.8 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      7.8 : 1.0\n",
            "                      .i = True           Non-Bu : Bullyi =      6.6 : 1.0\n",
            "                 someone = True           Non-Bu : Bullyi =      6.6 : 1.0\n",
            "                    keep = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                   sorry = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                      ur = True           Bullyi : Non-Bu =      5.7 : 1.0\n",
            "                 libtard = True           Bullyi : Non-Bu =      5.4 : 1.0\n",
            "                   thing = True           Non-Bu : Bullyi =      5.4 : 1.0\n",
            "0.6163522012578616\n",
            "bullying precision: 0.5424836601307189\n",
            "bullying recall: 0.6148148148148148\n",
            "bullying F-measure: 0.5763888888888888\n",
            "not-bullying precision: 0.6848484848484848\n",
            "not-bullying recall: 0.6174863387978142\n",
            "not-bullying F-measure: 0.6494252873563219\n",
            "0.6383647798742138\n",
            "bullying precision: 0.7\n",
            "bullying recall: 0.25925925925925924\n",
            "bullying F-measure: 0.3783783783783784\n",
            "non-bullying precision: 0.6268656716417911\n",
            "non-bullying recall: 0.9180327868852459\n",
            "non-bullying F-measure: 0.7450110864745012\n",
            "pos precision: 0.39661016949152544\n",
            "pos recall: 0.8666666666666667\n",
            "pos F-measure: 0.5441860465116279\n",
            "neg precision: 0.6033898305084746\n",
            "neg recall: 0.9726775956284153\n",
            "neg F-measure: 0.7447698744769874\n",
            "pos precision: 0.6036036036036037\n",
            "pos recall: 0.4962962962962963\n",
            "pos F-measure: 0.5447154471544716\n",
            "neg precision: 0.6033898305084746\n",
            "neg recall: 0.9726775956284153\n",
            "neg F-measure: 0.7447698744769874\n",
            "Most Informative Features\n",
            "       ('piece', 'shit') = True           Bullyi : Non-Bu =     18.1 : 1.0\n",
            "  ('worthless', 'piece') = True           Bullyi : Non-Bu =     12.2 : 1.0\n",
            "           ('low', 'iq') = True           Bullyi : Non-Bu =      9.2 : 1.0\n",
            "   ('fucking', 'retard') = True           Bullyi : Non-Bu =      3.4 : 1.0\n",
            "     ('fucking', 'cunt') = True           Bullyi : Non-Bu =      3.4 : 1.0\n",
            "        ('fuck', 'goat') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "          ('fag', 'lol') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "     ('asshole', 'like') = True           Bullyi : Non-Bu =      2.4 : 1.0\n",
            "           ('gon', 'na') = True           Bullyi : Non-Bu =      2.1 : 1.0\n",
            "   ('pathetic', 'loser') = True           Bullyi : Non-Bu =      1.8 : 1.0\n",
            "0.627177700348432\n",
            "bullying precision: 0.5490196078431373\n",
            "bullying recall: 0.25\n",
            "bullying F-measure: 0.34355828220858897\n",
            "not-bullying precision: 0.6440677966101694\n",
            "not-bullying recall: 0.8685714285714285\n",
            "not-bullying F-measure: 0.7396593673965935\n",
            "Most Informative Features\n",
            "                     low = True           Bullyi : Non-Bu =      8.3 : 1.0\n",
            "                 someone = True           Non-Bu : Bullyi =      7.3 : 1.0\n",
            "                   sorry = True           Bullyi : Non-Bu =      6.5 : 1.0\n",
            "                      ur = True           Bullyi : Non-Bu =      6.5 : 1.0\n",
            "                 libtard = True           Bullyi : Non-Bu =      6.3 : 1.0\n",
            "               worthless = True           Bullyi : Non-Bu =      5.8 : 1.0\n",
            "                  retard = True           Bullyi : Non-Bu =      5.6 : 1.0\n",
            "                  person = True           Non-Bu : Bullyi =      5.6 : 1.0\n",
            "                   piece = True           Bullyi : Non-Bu =      5.5 : 1.0\n",
            "                      iq = True           Bullyi : Non-Bu =      5.2 : 1.0\n",
            "0.6794425087108014\n",
            "bullying precision: 0.5923076923076923\n",
            "bullying recall: 0.6637931034482759\n",
            "bullying F-measure: 0.6260162601626016\n",
            "not-bullying precision: 0.7515923566878981\n",
            "not-bullying recall: 0.6900584795321637\n",
            "not-bullying F-measure: 0.7195121951219512\n",
            "0.686411149825784\n",
            "bullying precision: 0.76\n",
            "bullying recall: 0.3275862068965517\n",
            "bullying F-measure: 0.45783132530120485\n",
            "non-bullying precision: 0.6708860759493671\n",
            "non-bullying recall: 0.9298245614035088\n",
            "non-bullying F-measure: 0.7794117647058824\n",
            "pos precision: 0.35714285714285715\n",
            "pos recall: 0.7758620689655172\n",
            "pos F-measure: 0.48913043478260876\n",
            "neg precision: 0.6428571428571429\n",
            "neg recall: 0.9473684210526315\n",
            "neg F-measure: 0.7659574468085107\n",
            "pos precision: 0.6296296296296297\n",
            "pos recall: 0.5862068965517241\n",
            "pos F-measure: 0.6071428571428572\n",
            "neg precision: 0.6403162055335968\n",
            "neg recall: 0.9473684210526315\n",
            "neg F-measure: 0.7641509433962264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GY1T-sOZ0mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}